global:
  deployment: blue
  pipeline: helm

replicaCount: 4
revisionHistoryLimit: 0

## PodDisruptionBudget
## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
# maxUnavailable: 1

image:
  repository: localhost:32000/mathapi
  tag: latest
  pullPolicy: Always

service:
  type: ClusterIP
  annotations: {}
  labels: {}
  name: http
  externalPort: 80
  internalPort: 5000

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: traefik
    # kubernetes.io/tls-acme: "true"
  path: /
  hosts:
    - mathapi.danielpopov.com
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

## Probes
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
readinessProbe:
  path: /health_check
  # port: 9000
  initialDelaySeconds: 0
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

livenessProbe:
  path: /health_check
  # port: 9000
  initialDelaySeconds: 0
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

## Configure resource requests and limits
## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
resources: {}
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

podAnnotations: {}

## Override docker entrypoint
command: []

## Additional command line arguments to pass to images binary
extraArgs: {}

## Additional environmental variables to pass to container
extraEnvs:
  - name: FLASK_ENV
    value: "production"
  - name: DATABASE_URI
    valueFrom:
      secretKeyRef:
        name: mathapi-secrets
        key: database_uri
  - name: SMTP_PASSWORD
    valueFrom:
      secretKeyRef:
        name: mathapi-secrets
        key: smtp_password

## Additional volumeMounts to the main container.
extraVolumeMounts: []
  # - name: mount
  #   mountPath: /mnt

## Additional volumes to the pod.
extraVolumes: []
  # - name: volume
  #   emptyDir: {}

nodeSelector: {}

tolerations: []

affinity: {}

serviceAccount:
  create: false
  name: ""

secretFiles: {}
  # gcloud:
  #   mountPath: /etc/gcloud/key.json
  #   subPath: key.json
  #   files:
  #     json.key: base64encSecret

autoscaling:
  enabled: false
  minReplicas: 2
  maxReplicas: 11
  cpuPercentage: 75

redis:
  enabled: true
  usePassword: false
  cluster:
    enabled: false

monitoring:
  enabled: true

kibana:
  enabled: true
  service:
    type: ClusterIP
    loadBalancerIP: ""
    port: 5601
    nodePort: ""
    labels: {}
    annotations: {}
    loadBalancerSourceRanges: []
    httpPortName: http

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      ingress.kubernetes.io/auth-type: "basic"
      ingress.kubernetes.io/auth-secret: "admin-authsecret"
    hosts:
      - "mathapi-kibana.danielpopov.com"
    tls: []

postgresql-backup:
  enabled: false

elasticsearch:
  # Permit co-located instances for solitary minikube virtual machines.
  antiAffinity: "soft"

  # Shrink default JVM heap.
  esJavaOpts: "-Xmx128m -Xms128m"

  # Allocate smaller chunks of memory per pod.
  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "1000m"
      memory: "512M"

  # Request smaller persistent volumes.
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: "microk8s-hostpath"
    resources:
      requests:
        storage: 200M

logstash:
  extraPorts:
    - name: json
      containerPort: 5959
  persistence:
    enabled: true

  logstashConfig:
    logstash.yml: |
      http.host: 0.0.0.0
      xpack.monitoring.enabled: false
  logstashPipeline:
    uptime.conf: |
      input { tcp { codec => json port => 5959 } }
      filter {
        grok {
          match => { "message" => "%{HOSTNAME:remote_ip}.*\[%{HTTPDATE:date}\] \"%{WORD:request_method} %{DATA:request_path} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:response_length} \"%{DATA:request_referer}\" \"%{DATA:user_agent}\"" }
        }
      }
      output { elasticsearch { hosts => ["http://elasticsearch-master:9200"] } }

kube-prometheus-stack:
  grafana:
    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: traefik
      hosts:
        - "mathapi-monitoring.danielpopov.com"
      labels: {}
      path: /
      tls: []

  prometheus:
    prometheusSpec:
      additionalScrapeConfigs:
       - job_name: scrape-mathapi
         scrape_interval: 3s
         static_configs:
           - targets: ['mathapi-python:80']
         basic_auth:
           username: mathapi
           password: mathapi123
        
sentry:
  enabled: true
  sentry:
    worker:
      replicas: 2
  nginx:
    enabled: false
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: traefik
      #kubernetes.io/ingress.class: nginx
      #nginx.ingress.kubernetes.io/use-regex: "true"
    hostname: mathapi-sentry.danielpopov.com
  redis:
    enabled: false
  externalRedis:
    host: mathapi-redis-master
    port: 6379
  clickhouse:
    enabled: true
    replicaCount: 1
    clickhouse:
      imageVersion: "20.8.9.6"
      replicaCount: 1
      configmap:
        remote_servers:
          internal_replication: false
      persistentVolumeClaim:
        enabled: true
        dataPersistentVolume:
          enabled: true
          accessModes:
          - "ReadWriteOnce"
          storage: "2Gi"
  kafka:
    enabled: true
    replicaCount: 1
    allowPlaintextListener: true
    defaultReplicationFactor: 1
    offsetsTopicReplicationFactor: 1
    transactionStateLogReplicationFactor: 1
    transactionStateLogMinIsr: 1
    # 50 MB
    maxMessageBytes: "50000000"
    # 50 MB
    socketRequestMaxBytes: "50000000"

    service:
      port: 9092
  rabbitmq:
    enabled: true
    replicaCount: 1
    
postgresql:
  enabled: true
  metrics.enabled: true
  postgresqlDatabase: mathapi-production

  networkPolicy:
    enabled: true

    ## The Policy model to apply. When set to false, only pods with the correct
    ## client label will have network access to the port PostgreSQL is listening
    ## on. When true, PostgreSQL will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: false

    ## if explicitNamespacesSelector is missing or set to {}, only client Pods that are in the networkPolicy's namespace
    ## and that match other criteria, the ones that have the good label, can reach the DB.
    ## But sometimes, we want the DB to be accessible to clients from other namespaces, in this case, we can use this
    ## LabelSelector to select these namespaces, note that the networkPolicy's namespace should also be explicitly added.
    ##
    explicitNamespacesSelector:
      matchLabels:
        app.kubernetes.io/instance: "mathapi"
        app.kubernetes.io/name: "python"
      # matchExpressions:
        # - {key: role, operator: In, values: [frontend]}
 

